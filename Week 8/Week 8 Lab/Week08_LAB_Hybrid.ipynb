{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Week 8: Data Pipeline & CRUD (SQL)\n",
    "## CST1510 ‚Äî Multi-Domain Intelligence Platform\n",
    "\n",
    "**Building Your Database Layer**\n",
    "\n",
    "<hr style=\"border:2px solid #0EA5E9\">\n",
    "\n",
    "### What You'll Build This Week\n",
    "\n",
    "This week, you're transitioning from **file-based storage** (`users.txt`) to a **professional database system** (SQLite). By the end of this lab, you will have:\n",
    "\n",
    "1.  **Migrated** your Week 7 users from `users.txt` ‚Üí SQLite database\n",
    "2.  **Created** database tables for all three domains (cyber_incidents, datasets_metadata, it_tickets)\n",
    "3.  **Loaded** CSV data using pandas\n",
    "4.  **Implemented** CRUD operations (Create, Read, Update, Delete) using Python functions\n",
    "5.  **Secured** your queries against SQL injection attacks\n",
    "6.  **Tested** your database with real-world queries\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By completing this lab, you will:\n",
    "\n",
    "- Understand **why databases are better** than text files for data storage\n",
    "- Learn how to **connect to SQLite** using Python's built-in `sqlite3` module\n",
    "- Write **SQL CREATE TABLE** statements to define your data structure\n",
    "- Implement **CRUD operations** using Python functions\n",
    "- Use **parameterized queries** to prevent SQL injection\n",
    "- Load **CSV files** efficiently using pandas\n",
    "- Query your database to extract **meaningful insights**\n",
    "\n",
    "###  Beginner Tip\n",
    "\n",
    "Think of a database like a **super-powered Excel file** that:\n",
    "- Lives on disk (persists data)\n",
    "- Lets you search, add, update, and delete data **without reading the whole file**\n",
    "- Can link related data together (users ‚Üí incidents)\n",
    "- Protects against data corruption\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part0",
   "metadata": {},
   "source": [
    "## Part 0: Prerequisites & Setup\n",
    "\n",
    "### Step 0.1: Check Your Project Structure\n",
    "\n",
    "Before starting, make sure your project follows this structure:\n",
    "\n",
    "```\n",
    "CW2_M0123456_CST1510/\n",
    "‚îÇ\n",
    "‚îú‚îÄ app/\n",
    "‚îÇ  ‚îî‚îÄ data/              # Your database functions will go here\n",
    "‚îÇ\n",
    "‚îú‚îÄ DATA/                 # IMPORTANT: Uppercase DATA folder\n",
    "‚îÇ  ‚îú‚îÄ users.txt          # From Week 7\n",
    "‚îÇ  ‚îú‚îÄ cyber_incidents.csv\n",
    "‚îÇ  ‚îú‚îÄ datasets_metadata.csv\n",
    "‚îÇ  ‚îú‚îÄ it_tickets.csv\n",
    "‚îÇ  ‚îî‚îÄ intelligence_platform.db  # Will be created by your code\n",
    "‚îÇ\n",
    "‚îî‚îÄ requirements.txt\n",
    "```\n",
    "\n",
    "### Step 0.2: Install Required Libraries\n",
    "\n",
    "We'll use:\n",
    "- `sqlite3` ‚Üí **Built-in** to Python (no install needed!)\n",
    "- `pandas` ‚Üí For easy CSV loading\n",
    "- `bcrypt` ‚Üí For password hashing (from Week 7)\n",
    "\n",
    "Run this cell to install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "install",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install pandas bcrypt # in your project environment you just use pip install pandas bcrypt without the !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "### Step 0.3: Import Modules and Define Constants\n",
    "\n",
    "Let's import everything we need and set up our paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "imports_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Imports successful!\n",
      " DATA folder: D:\\MDX\\CW2_CST1510_M01087113_Week_7_12\\Week 8\\app\\data\\DATA\n",
      " Database will be created at: D:\\MDX\\CW2_CST1510_M01087113_Week_7_12\\Week 8\\app\\data\\DATA\\intelligence_platform.db\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import bcrypt\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = Path(\"DATA\")\n",
    "DB_PATH = DATA_DIR / \"intelligence_platform.db\"\n",
    "\n",
    "# Create DATA folder if it doesn't exist\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\" Imports successful!\")\n",
    "print(f\" DATA folder: {DATA_DIR.resolve()}\")\n",
    "print(f\" Database will be created at: {DB_PATH.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "file_organization",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## IMPORTANT: From One File to Many Files\n",
    "\n",
    "### Understanding the Transition\n",
    "\n",
    "**In Week 7**, you created a single file (`auth.py`) with all your authentication functions. This works great for small projects!\n",
    "\n",
    "**In Week 8+**, your project is growing, so we're organizing code into **multiple files** for better organization. This is how professional developers work!\n",
    "\n",
    "### Why Multiple Files?\n",
    "\n",
    "| Single File (Week 7) | Multiple Files (Week 8+) |\n",
    "|---------------------|-------------------------|\n",
    "|  Simple to start | Better organization |\n",
    "|  Easy to find everything |  Easier to maintain |\n",
    "|  Gets messy as code grows |  Team-friendly |\n",
    "|  Hard to reuse code |  Reusable modules |\n",
    "|  Difficult to test |  Easy to test |\n",
    "\n",
    "### Beginner Analogy\n",
    "\n",
    "Think of it like organizing your closet:\n",
    "- **Week 7**: Everything in one drawer (works when you don't have much)\n",
    "- **Week 8+**: Separate drawers for shirts, pants, socks (much better as your wardrobe grows!)\n",
    "\n",
    "---\n",
    "\n",
    "##  Your Week 8 File Organization\n",
    "\n",
    "### Complete Project Structure\n",
    "\n",
    "```\n",
    "CW2_M0123456_CST1510/\n",
    "‚îÇ\n",
    "‚îú‚îÄ app/\n",
    "‚îÇ  ‚îú‚îÄ data/                    # Database layer (Model in MVC)\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ __init__.py           # Makes this a Python package\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ db.py                 # Database connection functions\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ schema.py             # CREATE TABLE statements\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ users.py              # User CRUD functions\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ incidents.py          # Incident CRUD functions\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ datasets.py           # Dataset CRUD functions\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ tickets.py            # Ticket CRUD functions\n",
    "‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ services/                # Business logic layer\n",
    "‚îÇ     ‚îú‚îÄ __init__.py\n",
    "‚îÇ     ‚îî‚îÄ user_service.py       # User migration & auth functions\n",
    "‚îÇ\n",
    "‚îú‚îÄ DATA/                       # Data files (UPPERCASE)\n",
    "‚îÇ  ‚îú‚îÄ users.txt                # From Week 7\n",
    "‚îÇ  ‚îú‚îÄ cyber_incidents.csv\n",
    "‚îÇ  ‚îú‚îÄ datasets_metadata.csv\n",
    "‚îÇ  ‚îú‚îÄ it_tickets.csv\n",
    "‚îÇ  ‚îî‚îÄ intelligence_platform.db # Created by your code\n",
    "‚îÇ\n",
    "‚îú‚îÄ docs/\n",
    "‚îÇ  ‚îî‚îÄ README.md                # Project documentation\n",
    "‚îÇ\n",
    "‚îú‚îÄ main.py                     # Demo script (entry point)\n",
    "‚îú‚îÄ requirements.txt            # Python dependencies\n",
    "‚îî‚îÄ .gitignore                  # Git ignore file\n",
    "```\n",
    "\n",
    "### What Goes in Each File?\n",
    "\n",
    "#### `app/data/db.py` ‚Äî Database Connection\n",
    "**Purpose**: Connect to and close the database\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "DB_PATH = Path(\"DATA\") / \"intelligence_platform.db\"\n",
    "\n",
    "def connect_database(db_path=DB_PATH):\n",
    "    \"\"\"Connect to SQLite database.\"\"\"\n",
    "    return sqlite3.connect(str(db_path))\n",
    "```\n",
    "\n",
    "####  `app/data/schema.py` ‚Äî Table Definitions\n",
    "**Purpose**: All CREATE TABLE statements\n",
    "\n",
    "```python\n",
    "def create_users_table(conn):\n",
    "    \"\"\"Create users table.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS users (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            username TEXT NOT NULL UNIQUE,\n",
    "            password_hash TEXT NOT NULL,\n",
    "            role TEXT DEFAULT 'user'\n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "def create_all_tables(conn):\n",
    "    \"\"\"Create all tables.\"\"\"\n",
    "    create_users_table(conn)\n",
    "    create_cyber_incidents_table(conn)\n",
    "    create_datasets_metadata_table(conn)\n",
    "    create_it_tickets_table(conn)\n",
    "```\n",
    "\n",
    "#### `app/data/users.py` ‚Äî User CRUD Operations\n",
    "**Purpose**: All functions for managing users\n",
    "\n",
    "```python\n",
    "from app.data.db import connect_database\n",
    "\n",
    "def get_user_by_username(username):\n",
    "    \"\"\"Retrieve user by username.\"\"\"\n",
    "    conn = connect_database()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"SELECT * FROM users WHERE username = ?\",\n",
    "        (username,)\n",
    "    )\n",
    "    user = cursor.fetchone()\n",
    "    conn.close()\n",
    "    return user\n",
    "\n",
    "def insert_user(username, password_hash, role='user'):\n",
    "    \"\"\"Insert new user.\"\"\"\n",
    "    conn = connect_database()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"INSERT INTO users (username, password_hash, role) VALUES (?, ?, ?)\",\n",
    "        (username, password_hash, role)\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "```\n",
    "\n",
    "####  `app/data/incidents.py` ‚Äî Incident CRUD Operations\n",
    "**Purpose**: All functions for managing cyber incidents\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from app.data.db import connect_database\n",
    "\n",
    "def insert_incident(date, incident_type, severity, status, description, reported_by=None):\n",
    "    \"\"\"Insert new incident.\"\"\"\n",
    "    conn = connect_database()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO cyber_incidents \n",
    "        (date, incident_type, severity, status, description, reported_by)\n",
    "        VALUES (?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", (date, incident_type, severity, status, description, reported_by))\n",
    "    conn.commit()\n",
    "    incident_id = cursor.lastrowid\n",
    "    conn.close()\n",
    "    return incident_id\n",
    "\n",
    "def get_all_incidents():\n",
    "    \"\"\"Get all incidents as DataFrame.\"\"\"\n",
    "    conn = connect_database()\n",
    "    df = pd.read_sql_query(\n",
    "        \"SELECT * FROM cyber_incidents ORDER BY id DESC\",\n",
    "        conn\n",
    "    )\n",
    "    conn.close()\n",
    "    return df\n",
    "```\n",
    "\n",
    "#### üìÑ `app/services/user_service.py` ‚Äî User Business Logic\n",
    "**Purpose**: Authentication and user migration\n",
    "\n",
    "```python\n",
    "import bcrypt\n",
    "from pathlib import Path\n",
    "from app.data.db import connect_database\n",
    "from app.data.users import get_user_by_username, insert_user\n",
    "from app.data.schema import create_users_table\n",
    "\n",
    "def register_user(username, password, role='user'):\n",
    "    \"\"\"Register new user with password hashing.\"\"\"\n",
    "    # Hash password\n",
    "    password_hash = bcrypt.hashpw(\n",
    "        password.encode('utf-8'),\n",
    "        bcrypt.gensalt()\n",
    "    ).decode('utf-8')\n",
    "    \n",
    "    # Insert into database\n",
    "    insert_user(username, password_hash, role)\n",
    "    return True, f\"User '{username}' registered successfully.\"\n",
    "\n",
    "def login_user(username, password):\n",
    "    \"\"\"Authenticate user.\"\"\"\n",
    "    user = get_user_by_username(username)\n",
    "    if not user:\n",
    "        return False, \"User not found.\"\n",
    "    \n",
    "    # Verify password\n",
    "    stored_hash = user[2]  # password_hash column\n",
    "    if bcrypt.checkpw(password.encode('utf-8'), stored_hash.encode('utf-8')):\n",
    "        return True, f\"Login successful!\"\n",
    "    return False, \"Incorrect password.\"\n",
    "\n",
    "def migrate_users_from_file(filepath='DATA/users.txt'):\n",
    "    \"\"\"Migrate users from text file to database.\"\"\"\n",
    "    # ... migration logic ...\n",
    "```\n",
    "\n",
    "#### `main.py` ‚Äî Demo Script (Entry Point)\n",
    "**Purpose**: Demonstrate all functionality\n",
    "\n",
    "```python\n",
    "from app.data.db import connect_database\n",
    "from app.data.schema import create_all_tables\n",
    "from app.services.user_service import register_user, login_user, migrate_users_from_file\n",
    "from app.data.incidents import insert_incident, get_all_incidents\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Week 8: Database Demo\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Setup database\n",
    "    conn = connect_database()\n",
    "    create_all_tables(conn)\n",
    "    conn.close()\n",
    "    \n",
    "    # 2. Migrate users\n",
    "    migrate_users_from_file()\n",
    "    \n",
    "    # 3. Test authentication\n",
    "    success, msg = register_user(\"alice\", \"SecurePass123!\", \"analyst\")\n",
    "    print(msg)\n",
    "    \n",
    "    success, msg = login_user(\"alice\", \"SecurePass123!\")\n",
    "    print(msg)\n",
    "    \n",
    "    # 4. Test CRUD\n",
    "    incident_id = insert_incident(\n",
    "        \"2024-11-05\",\n",
    "        \"Phishing\",\n",
    "        \"High\",\n",
    "        \"Open\",\n",
    "        \"Suspicious email detected\",\n",
    "        \"alice\"\n",
    "    )\n",
    "    print(f\"Created incident #{incident_id}\")\n",
    "    \n",
    "    # 5. Query data\n",
    "    df = get_all_incidents()\n",
    "    print(f\"Total incidents: {len(df)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  Development Workflow\n",
    "\n",
    "### How to Work with This Structure\n",
    "\n",
    "**While developing in this notebook:**\n",
    "1. Write and test functions here first\n",
    "2. Make sure each function works correctly\n",
    "3. Once tested, copy functions to the appropriate file\n",
    "\n",
    "**After the notebook:**\n",
    "1. Create the file structure shown above\n",
    "2. Copy functions from this notebook to their respective files\n",
    "3. Add proper imports between files\n",
    "4. Test by running `main.py`\n",
    "\n",
    "### Beginner Tip: Don't Worry!\n",
    "\n",
    "**For now**, focus on learning the functions in this notebook. At the end, we'll show you exactly how to organize everything into files. Think of this notebook as your **workshop** where you build and test each piece before assembling the final project.\n",
    "\n",
    "---\n",
    "\n",
    "## Creating Python Packages\n",
    "\n",
    "### What is `__init__.py`?\n",
    "\n",
    "You'll notice `__init__.py` files in the structure. These make folders into **Python packages** so you can import from them.\n",
    "\n",
    "**Create empty `__init__.py` files:**\n",
    "```bash\n",
    "touch app/__init__.py\n",
    "touch app/data/__init__.py\n",
    "touch app/services/__init__.py\n",
    "```\n",
    "\n",
    "Or in Python:\n",
    "```python\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"app/__init__.py\").touch()\n",
    "Path(\"app/data/__init__.py\").touch()\n",
    "Path(\"app/services/__init__.py\").touch()\n",
    "```\n",
    "\n",
    "### How Imports Work\n",
    "\n",
    "Once you have this structure, you can import like this:\n",
    "\n",
    "```python\n",
    "# From main.py\n",
    "from app.data.db import connect_database\n",
    "from app.data.incidents import insert_incident, get_all_incidents\n",
    "from app.services.user_service import register_user, login_user\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "why_db",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Why Move from Files to Databases?\n",
    "\n",
    "### Understanding the Problem\n",
    "\n",
    "In Week 7, you stored users in `users.txt`. This works for small projects, but has serious limitations:\n",
    "\n",
    "| **File Storage** (`users.txt`) | **Database** (`intelligence_platform.db`) |\n",
    "|--------------------------------|-------------------------------------------|\n",
    "| Slow search (must read entire file) | ‚ö° Fast search with SQL queries |\n",
    "| No relationships between data |  Link users to incidents, tickets, etc. |\n",
    "| Risk of corruption | ACID-safe (Atomicity, Consistency, Isolation, Durability) |\n",
    "| Manual parsing required | Powerful query language (SQL) |\n",
    "| Single-user access | Multi-user support |\n",
    "\n",
    "### Your Database Schema\n",
    "\n",
    "You'll create **4 tables**:\n",
    "\n",
    "1. **`users`** ‚Äî User accounts with authentication\n",
    "2. **`cyber_incidents`** ‚Äî Security incidents (your chosen domain)\n",
    "3. **`datasets_metadata`** ‚Äî Dataset information\n",
    "4. **`it_tickets`** ‚Äî IT support tickets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2",
   "metadata": {},
   "source": [
    "## Part 2: Database Connection Functions\n",
    "\n",
    "### Step 2.1: Create Connection Function\n",
    "\n",
    "First, we need a function to connect to our database. This function will:\n",
    "- Create the database file if it doesn't exist\n",
    "- Return a connection object that we can use to run SQL commands\n",
    "\n",
    " **Beginner Tip**: Think of `conn` (connection) as a phone line to your database. You need it to send commands and get responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "connect_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_database(db_path=DB_PATH):\n",
    "    \"\"\"\n",
    "    Connect to the SQLite database.\n",
    "    Creates the database file if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        db_path: Path to the database file\n",
    "        \n",
    "    Returns:\n",
    "        sqlite3.Connection: Database connection object\n",
    "    \"\"\"\n",
    "    return sqlite3.connect(str(db_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Create Database Tables\n",
    "\n",
    "### Step 3.1: Create the `users` Table\n",
    "\n",
    "Let's start by creating a table for users. This table will store:\n",
    "- `id` ‚Äî Unique identifier (auto-incremented)\n",
    "- `username` ‚Äî User's login name (must be unique)\n",
    "- `password_hash` ‚Äî Hashed password (from bcrypt)\n",
    "- `role` ‚Äî User role (e.g., 'user', 'analyst', 'admin')\n",
    "\n",
    "üí° **Beginner Tip**: `CREATE TABLE IF NOT EXISTS` means \"create this table only if it doesn't already exist\". This prevents errors if you run the code multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "create_users_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_users_table(conn):\n",
    "    \"\"\"\n",
    "    Create the users table if it doesn't exist.\n",
    "    \n",
    "    This is a COMPLETE IMPLEMENTATION as an example.\n",
    "    Study this carefully before implementing the other tables!\n",
    "    \n",
    "    Args:\n",
    "        conn: Database connection object\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # SQL statement to create users table\n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        username TEXT NOT NULL UNIQUE,\n",
    "        password_hash TEXT NOT NULL,\n",
    "        role TEXT DEFAULT 'user',\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ Users table created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "207487ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Users table created successfully!\n"
     ]
    }
   ],
   "source": [
    "# 1. Create the connection \"phone line\"\n",
    "conn = connect_database()\n",
    "\n",
    "# 2. Call the function you just wrote\n",
    "create_users_table(conn)\n",
    "\n",
    "# 3. Close the connection (Good habit!)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_domain_tables",
   "metadata": {},
   "source": [
    "### Step 3.2: Create Domain Tables\n",
    "\n",
    "Now let's create tables for your three domains. Each table will have columns matching your CSV files.\n",
    "\n",
    "#### Security Note: Foreign Keys\n",
    "\n",
    "Notice that `cyber_incidents` has a `FOREIGN KEY` that references `users(username)`. This creates a **relationship** between tables:\n",
    "- Each incident can be linked to the user who reported it\n",
    "- This is one of the key advantages of databases over text files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "create_domain_tables_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cyber_incidents_table(conn):\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Standard schema required by the lab\n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS cyber_incidents (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        date TEXT,\n",
    "        incident_type TEXT,\n",
    "        severity TEXT,\n",
    "        status TEXT,\n",
    "        description TEXT,\n",
    "        reported_by TEXT,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        FOREIGN KEY (reported_by) REFERENCES users(username)\n",
    "    )\n",
    "    \"\"\"\n",
    "    cursor.execute(sql)\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ Cyber Incidents table created!\")\n",
    "\n",
    "def create_datasets_metadata_table(conn):\n",
    "    \"\"\"\n",
    "    Create the datasets_metadata table.\n",
    "    \n",
    "    TODO: Implement this function following the users table example.\n",
    "    \n",
    "    Required columns:\n",
    "    - id: INTEGER PRIMARY KEY AUTOINCREMENT\n",
    "    - dataset_name: TEXT NOT NULL\n",
    "    - category: TEXT (e.g., 'Threat Intelligence', 'Network Logs')\n",
    "    - source: TEXT (origin of the dataset)\n",
    "    - last_updated: TEXT (format: YYYY-MM-DD)\n",
    "    - record_count: INTEGER\n",
    "    - file_size_mb: REAL\n",
    "    - created_at: TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    \"\"\"\n",
    "    # TODO: Implement following the users table pattern\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    create_table_sql = '''\n",
    "    CREATE TABLE IF NOT EXISTS datasets_metadata (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        dataset_name TEXT NOT NULL,\n",
    "        category TEXT,\n",
    "        source TEXT,\n",
    "        last_updated TEXT,\n",
    "        record_count INTEGER,\n",
    "        file_size_mb REAL,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "def create_it_tickets_table(conn):\n",
    "    \"\"\"\n",
    "    Create the it_tickets table.\n",
    "    \n",
    "    TODO: Implement this function following the users table example.\n",
    "    \n",
    "    Required columns:\n",
    "    - id: INTEGER PRIMARY KEY AUTOINCREMENT\n",
    "    - ticket_id: TEXT UNIQUE NOT NULL\n",
    "    - priority: TEXT (e.g., 'Critical', 'High', 'Medium', 'Low')\n",
    "    - status: TEXT (e.g., 'Open', 'In Progress', 'Resolved', 'Closed')\n",
    "    - category: TEXT (e.g., 'Hardware', 'Software', 'Network')\n",
    "    - subject: TEXT NOT NULL\n",
    "    - description: TEXT\n",
    "    - created_date: TEXT (format: YYYY-MM-DD)\n",
    "    - resolved_date: TEXT\n",
    "    - assigned_to: TEXT\n",
    "    - created_at: TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    \"\"\"\n",
    "    # TODO: Implement following the users table pattern\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    create_table_sql = '''\n",
    "    CREATE TABLE IF NOT EXISTS it_tickets (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        ticket_id TEXT UNIQUE NOT NULL,\n",
    "        priority TEXT,\n",
    "        status TEXT,\n",
    "        category TEXT,\n",
    "        subject TEXT NOT NULL,\n",
    "        description TEXT,\n",
    "        created_date TEXT,\n",
    "        resolved_date TEXT,\n",
    "        assigned_to TEXT,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    '''\n",
    "\n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "    print('‚úÖ Users table created successfully!')\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Migrate Users from Week 7\n",
    "\n",
    "### Step 4.1: Understanding Migration\n",
    "\n",
    "**Migration** means copying data from an old format (text file) to a new format (database table).\n",
    "\n",
    "Your `users.txt` file from Week 7 has this format:\n",
    "```\n",
    "username,password_hash,role\n",
    "alice,$2b$12$...,analyst\n",
    "bob,$2b$12$...,user\n",
    "```\n",
    "\n",
    "We need to:\n",
    "1. Read each line from `users.txt`\n",
    "2. Parse the username, password_hash, and role\n",
    "3. INSERT each user into the `users` table\n",
    "\n",
    "### Step 4.2: Create Migration Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "migrate_users",
   "metadata": {},
   "outputs": [],
   "source": [
    "def migrate_users_from_file(conn, filepath=DATA_DIR / \"users.txt\"):\n",
    "    \"\"\"\n",
    "    Migrate users from users.txt to the database.\n",
    "    \n",
    "    This is a COMPLETE IMPLEMENTATION as an example.\n",
    "    \n",
    "    Args:\n",
    "        conn: Database connection\n",
    "        filepath: Path to users.txt file\n",
    "    \"\"\"\n",
    "    if not filepath.exists():\n",
    "        print(f\"‚ö†Ô∏è  File not found: {filepath}\")\n",
    "        print(\"   No users to migrate.\")\n",
    "        return\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    migrated_count = 0\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            parts = line.split(',')\n",
    "            if len(parts) >= 2:\n",
    "                username = parts[0]\n",
    "                password_hash = parts[1]\n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    cursor.execute(\n",
    "                        \"INSERT OR IGNORE INTO users (username, password_hash, role) VALUES (?, ?, ?)\",\n",
    "                        (username, password_hash, 'user')\n",
    "                    )\n",
    "                    if cursor.rowcount > 0:\n",
    "                        migrated_count += 1\n",
    "                except sqlite3.Error as e:\n",
    "                    print(f\"Error migrating user {username}: {e}\")\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"‚úÖ Migrated {migrated_count} users from {filepath.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify_migration",
   "metadata": {},
   "source": [
    "### Step 4.3: Verify Migration\n",
    "\n",
    "Let's check that the users were actually inserted into the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4244c04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  File not found: DATA\\users.txt\n",
      "   No users to migrate.\n"
     ]
    }
   ],
   "source": [
    "conn = connect_database()\n",
    "migrate_users_from_file(conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "verify_migration_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Users in database:\n",
      "ID    Username        Role      \n",
      "-----------------------------------\n",
      "\n",
      "Total users: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conn = connect_database()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "cursor.execute(\"SELECT id, username, role FROM users\")\n",
    "users = cursor.fetchall()\n",
    "\n",
    "print(\" Users in database:\")\n",
    "print(f\"{'ID':<5} {'Username':<15} {'Role':<10}\")\n",
    "print(\"-\" * 35)\n",
    "for user in users:\n",
    "    print(f\"{user[0]:<5} {user[1]:<15} {user[2]:<10}\")\n",
    "\n",
    "print(f\"\\nTotal users: {len(users)}\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Authentication Functions (Database-Backed)\n",
    "\n",
    "### Step 5.1: Register Function\n",
    "\n",
    "Now that users are in the database, we need to update our authentication to work with the database instead of `users.txt`.\n",
    "\n",
    "The `register()` function will:\n",
    "1. Check if username already exists\n",
    "2. Hash the password with bcrypt\n",
    "3. INSERT the new user into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "register_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_user(username, password, role=\"user\"):\n",
    "    \"\"\"\n",
    "    Register a new user in the database.\n",
    "    \n",
    "    This is a COMPLETE IMPLEMENTATION as an example.\n",
    "    \n",
    "    Args:\n",
    "        username: User's login name\n",
    "        password: Plain text password (will be hashed)\n",
    "        role: User role (default: 'user')\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (success: bool, message: str)\n",
    "    \"\"\"\n",
    "    conn = connect_database()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    \n",
    "    cursor.execute(\"SELECT * FROM users WHERE username = ?\", (username,))\n",
    "    if cursor.fetchone():\n",
    "        conn.close()\n",
    "        return False, f\"Username '{username}' already exists.\"\n",
    "    \n",
    "   \n",
    "    password_bytes = password.encode('utf-8')\n",
    "    salt = bcrypt.gensalt()\n",
    "    hashed = bcrypt.hashpw(password_bytes, salt)\n",
    "    password_hash = hashed.decode('utf-8')\n",
    "    \n",
    "  \n",
    "    cursor.execute(\n",
    "        \"INSERT INTO users (username, password_hash, role) VALUES (?, ?, ?)\",\n",
    "        (username, password_hash, role)\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    return True, f\"User '{username}' registered successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "login_func_section",
   "metadata": {},
   "source": [
    "### Step 5.2: Login Function\n",
    "\n",
    "The `login()` function will:\n",
    "1. Look up the user in the database\n",
    "2. Retrieve their stored password hash\n",
    "3. Verify the provided password against the hash using bcrypt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "login_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_user(username, password):\n",
    "    \"\"\"\n",
    "    Authenticate a user against the database.\n",
    "    \n",
    "    This is a COMPLETE IMPLEMENTATION as an example.\n",
    "    \n",
    "    Args:\n",
    "        username: User's login name\n",
    "        password: Plain text password to verify\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (success: bool, message: str)\n",
    "    \"\"\"\n",
    "    conn = connect_database()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "   \n",
    "    cursor.execute(\"SELECT * FROM users WHERE username = ?\", (username,))\n",
    "    user = cursor.fetchone()\n",
    "    conn.close()\n",
    "    \n",
    "    if not user:\n",
    "        return False, \"Username not found.\"\n",
    "    \n",
    "    \n",
    "    stored_hash = user[2]\n",
    "    password_bytes = password.encode('utf-8')\n",
    "    hash_bytes = stored_hash.encode('utf-8')\n",
    "    \n",
    "    if bcrypt.checkpw(password_bytes, hash_bytes):\n",
    "        return True, f\"Welcome, {username}!\"\n",
    "    else:\n",
    "        return False, \"Invalid password.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Load CSV Data with Pandas\n",
    "\n",
    "### Step 6.1: Understanding Bulk Loading\n",
    "\n",
    "Now that your tables exist, you can load the provided CSV files. Pandas makes this incredibly easy with the `to_sql()` method.\n",
    "\n",
    " **Beginner Tip**: \n",
    "- `if_exists='append'` means \"add to existing data\"\n",
    "- `if_exists='replace'` means \"delete old data and insert new\"\n",
    "- `index=False` means \"don't save the DataFrame index as a column\"\n",
    "\n",
    "### Step 6.2: Create CSV Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "load_csv_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_to_table(conn, csv_path, table_name):\n",
    "    \"\"\"\n",
    "    Load a CSV file into a database table using pandas.\n",
    "    \n",
    "    TODO: Implement this function.\n",
    "    \n",
    "    Args:\n",
    "        conn: Database connection\n",
    "        csv_path: Path to CSV file\n",
    "        table_name: Name of the target table\n",
    "        \n",
    "    Returns:\n",
    "        int: Number of rows loaded\n",
    "    \"\"\"\n",
    "    # TODO: Check if CSV file exists\n",
    "    if not csv_path.exists():\n",
    "        print(f'File not found: {csv_path}')\n",
    "        return 0\n",
    "    \n",
    "    # TODO: Read CSV using pandas.read_csv()\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # TODO: Use df.to_sql() to insert data\n",
    "    # Parameters: name=table_name, con=conn, if_exists='append', index=False\n",
    "    df.to_sql(name=table_name, con=conn, if_exists='append', index=False)\n",
    "    \n",
    "    # TODO: Print success message and return row count\n",
    "    print(f' Loaded {len(df)} into {table_name}')\n",
    "    return(len(df))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: CRUD Operations\n",
    "\n",
    "### Understanding CRUD\n",
    "\n",
    "**CRUD** stands for the four basic operations you can perform on database data:\n",
    "\n",
    "| Operation | SQL Command | What It Does |\n",
    "|-----------|-------------|-------------|\n",
    "| **C**reate | `INSERT` | Add new records |\n",
    "| **R**ead | `SELECT` | Retrieve existing records |\n",
    "| **U**pdate | `UPDATE` | Modify existing records |\n",
    "| **D**elete | `DELETE` | Remove records |\n",
    "\n",
    "###  Security: Parameterized Queries\n",
    "\n",
    "**CRITICAL**: Always use `?` placeholders and pass values as a tuple to prevent SQL injection attacks!\n",
    "\n",
    " **NEVER DO THIS** (vulnerable to SQL injection):\n",
    "```python\n",
    "query = f\"SELECT * FROM users WHERE username = '{username}'\"\n",
    "```\n",
    "\n",
    " **ALWAYS DO THIS** (safe):\n",
    "```python\n",
    "query = \"SELECT * FROM users WHERE username = ?\"\n",
    "cursor.execute(query, (username,))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 7.1: CREATE ‚Äî Insert New Incident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "create_incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_incident(conn, date, incident_type, severity, status, description, reported_by=None):\n",
    "    \"\"\"\n",
    "    Insert a new cyber incident into the database.\n",
    "    \n",
    "    TODO: Implement this function following the register_user() pattern.\n",
    "    \n",
    "    Args:\n",
    "        conn: Database connection\n",
    "        date: Incident date (YYYY-MM-DD)\n",
    "        incident_type: Type of incident\n",
    "        severity: Severity level\n",
    "        status: Current status\n",
    "        description: Incident description\n",
    "        reported_by: Username of reporter (optional)\n",
    "        \n",
    "    Returns:\n",
    "        int: ID of the inserted incident\n",
    "    \"\"\"\n",
    "    # TODO: Get cursor\n",
    "    cursor = conn.cursor()\n",
    "    # TODO: Write INSERT SQL with parameterized query\n",
    "    sql = \"\"\"\n",
    "        INSERT INTO cyber_incidents \n",
    "        (date, incident_type, severity, status, description, reported_by)\n",
    "        VALUES (?, ?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "    # TODO: Execute and commit\n",
    "    cursor.execute(sql, (date, incident_type, severity, status, description, reported_by))\n",
    "    conn.commit()\n",
    "    # TODO: Return cursor.lastrowid\n",
    "    return cursor.lastrowid\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "read_section",
   "metadata": {},
   "source": [
    "### Step 7.2: READ ‚Äî Query Incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "read_incidents",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_incidents(conn):\n",
    "    \"\"\"\n",
    "    Retrieve all incidents from the database.\n",
    "    \n",
    "    TODO: Implement using pandas.read_sql_query()\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: All incidents\n",
    "    \"\"\"\n",
    "    # TODO: Use pd.read_sql_query(\"SELECT * FROM cyber_incidents\", conn)\n",
    "    return pd.read_sql_query(\"SELECT * FROM cyber_incidents\", conn)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "update_section",
   "metadata": {},
   "source": [
    "### Step 7.3: UPDATE ‚Äî Modify Incident Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "update_incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_incident_status(conn, incident_id, new_status):\n",
    "    \"\"\"\n",
    "    Update the status of an incident.\n",
    "    \n",
    "    TODO: Implement UPDATE operation.\n",
    "    \"\"\"\n",
    "    # TODO: Write UPDATE SQL: UPDATE cyber_incidents SET status = ? WHERE id = ?\n",
    "    cursor = conn.cursor()\n",
    "    sql = \"UPDATE cyber_incidents SET status = ? WHERE id = ?\"\n",
    "\n",
    "    # TODO: Execute and commit\n",
    "    cursor.execute(sql, (new_status, incident_id))\n",
    "    conn.commit()\n",
    "\n",
    "    # TODO: Return cursor.rowcount\n",
    "    return cursor.rowcount\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delete_section",
   "metadata": {},
   "source": [
    "### Step 7.4: DELETE ‚Äî Remove Incident\n",
    "\n",
    " **WARNING**: DELETE is permanent! Always use a WHERE clause to avoid deleting all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "delete_incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_incident(conn, incident_id):\n",
    "    \"\"\"\n",
    "    Delete an incident from the database.\n",
    "    \n",
    "    TODO: Implement DELETE operation.\n",
    "    \"\"\"\n",
    "    # TODO: Write DELETE SQL: DELETE FROM cyber_incidents WHERE id = ?\n",
    "    cursor = conn.cursor()\n",
    "    sql = \"DELETE FROM cyber_incidents WHERE id = ?\"\n",
    "    # TODO: Execute and commit\n",
    "    cursor.execute(sql, (incident_id,))\n",
    "    conn.commit()\n",
    "    # TODO: Return cursor.rowcount\n",
    "    return cursor.rowcount\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Analytical Queries (The Big 6) - OPTIONAL it couuld be done with pandas\n",
    "\n",
    "### Step 8.1: Using GROUP BY for Aggregation\n",
    "\n",
    "Let's use the **Big 6 SQL clauses** to extract insights from your data:\n",
    "\n",
    "1. **SELECT** ‚Äî Choose what columns to return\n",
    "2. **FROM** ‚Äî Specify the table\n",
    "3. **WHERE** ‚Äî Filter individual rows\n",
    "4. **GROUP BY** ‚Äî Group rows for aggregation\n",
    "5. **HAVING** ‚Äî Filter aggregated groups\n",
    "6. **ORDER BY** ‚Äî Sort the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "analytical_queries",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Incidents by Type:\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n    SELECT incident_type, COUNT(*) as count\n    FROM cyber_incidents\n    GROUP BY incident_type\n    ORDER BY count DESC\n    ': no such table: cyber_incidents",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\sql.py:2664\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2663\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2664\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2665\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[31mOperationalError\u001b[39m: no such table: cyber_incidents",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatabaseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m conn = connect_database()\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Incidents by Type:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m df_by_type = \u001b[43mget_incidents_by_type_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_by_type)\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m High Severity Incidents by Status:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mget_incidents_by_type_count\u001b[39m\u001b[34m(conn)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mCount incidents by type.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mUses: SELECT, FROM, GROUP BY, ORDER BY\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33mSELECT incident_type, COUNT(*) as count\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33mFROM cyber_incidents\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33mGROUP BY incident_type\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33mORDER BY count DESC\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\sql.py:528\u001b[39m, in \u001b[36mread_sql_query\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\sql.py:2728\u001b[39m, in \u001b[36mSQLiteDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   2717\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   2718\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2719\u001b[39m     sql,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2726\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2727\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m-> \u001b[39m\u001b[32m2728\u001b[39m     cursor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2729\u001b[39m     columns = [col_desc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor.description]\n\u001b[32m   2731\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\sql.py:2676\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2673\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minner_exc\u001b[39;00m\n\u001b[32m   2675\u001b[39m ex = DatabaseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecution failed on sql \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2676\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mDatabaseError\u001b[39m: Execution failed on sql '\n    SELECT incident_type, COUNT(*) as count\n    FROM cyber_incidents\n    GROUP BY incident_type\n    ORDER BY count DESC\n    ': no such table: cyber_incidents"
     ]
    }
   ],
   "source": [
    "def get_incidents_by_type_count(conn):\n",
    "    \"\"\"\n",
    "    Count incidents by type.\n",
    "    Uses: SELECT, FROM, GROUP BY, ORDER BY\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT incident_type, COUNT(*) as count\n",
    "    FROM cyber_incidents\n",
    "    GROUP BY incident_type\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    return df\n",
    "\n",
    "def get_high_severity_by_status(conn):\n",
    "    \"\"\"\n",
    "    Count high severity incidents by status.\n",
    "    Uses: SELECT, FROM, WHERE, GROUP BY, ORDER BY\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT status, COUNT(*) as count\n",
    "    FROM cyber_incidents\n",
    "    WHERE severity = 'High'\n",
    "    GROUP BY status\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    return df\n",
    "\n",
    "def get_incident_types_with_many_cases(conn, min_count=5):\n",
    "    \"\"\"\n",
    "    Find incident types with more than min_count cases.\n",
    "    Uses: SELECT, FROM, GROUP BY, HAVING, ORDER BY\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT incident_type, COUNT(*) as count\n",
    "    FROM cyber_incidents\n",
    "    GROUP BY incident_type\n",
    "    HAVING COUNT(*) > ?\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn, params=(min_count,))\n",
    "    return df\n",
    "\n",
    "# Test: Run analytical queries\n",
    "conn = connect_database()\n",
    "\n",
    "print(\"\\n Incidents by Type:\")\n",
    "df_by_type = get_incidents_by_type_count(conn)\n",
    "print(df_by_type)\n",
    "\n",
    "print(\"\\n High Severity Incidents by Status:\")\n",
    "df_high_severity = get_high_severity_by_status(conn)\n",
    "print(df_high_severity)\n",
    "\n",
    "print(\"\\n Incident Types with Many Cases (>5):\")\n",
    "df_many_cases = get_incident_types_with_many_cases(conn, min_count=5)\n",
    "print(df_many_cases)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Complete Database Setup Script\n",
    "\n",
    "### Step 9.1: Create a Complete Setup Function\n",
    "\n",
    "Let's create a single function that sets up your entire database from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02f88650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Title', 'Date', 'Affiliations', 'Description', 'Response', 'Victims', 'Sponsor', 'Type', 'Category', 'Sources_1', 'Sources_2', 'Sources_3']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read just the first row to see column names\n",
    "df = pd.read_csv(DATA_DIR / \"cyber_incidents.csv\")\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING COMPLETE DATABASE SETUP\n",
      "============================================================\n",
      "\n",
      "[1/5] Connecting to database...\n",
      "\n",
      "[2/5] Creating database tables...\n",
      "‚úÖ Users table created successfully!\n",
      "‚úÖ Cyber Incidents table created!\n",
      "‚úÖ Users table created successfully!\n",
      "\n",
      "[3/5] Migrating users...\n",
      "‚úÖ Migrated 2 users from users.txt\n",
      "\n",
      "[4/5] Loading and Cleaning CSV data...\n",
      "‚úÖ Loaded 481 cleaned rows into 'cyber_incidents'\n",
      " Loaded 8 into datasets_metadata\n",
      " Loaded 6 into it_tickets\n",
      "\n",
      "[5/5] Verifying...\n",
      "‚úÖ IT Tickets Row Count: 6\n",
      "\n",
      "DATABASE SETUP COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "def setup_database_complete():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STARTING COMPLETE DATABASE SETUP\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    " \n",
    "    print(\"\\n[1/5] Connecting to database...\")\n",
    "    conn = connect_database()\n",
    "    \n",
    "    conn.execute(\"DROP TABLE IF EXISTS users\")\n",
    "    conn.execute(\"DROP TABLE IF EXISTS cyber_incidents\")\n",
    "    conn.execute(\"DROP TABLE IF EXISTS datasets_metadata\")\n",
    "    conn.execute(\"DROP TABLE IF EXISTS it_tickets\") \n",
    "    \n",
    "   \n",
    "    print(\"\\n[2/5] Creating database tables...\")\n",
    "    create_users_table(conn)\n",
    "    create_cyber_incidents_table(conn)\n",
    "    create_datasets_metadata_table(conn)\n",
    "    create_it_tickets_table(conn)\n",
    "    \n",
    "  \n",
    "    print(\"\\n[3/5] Migrating users...\")\n",
    "    try:\n",
    "        migrate_users_from_file(conn)\n",
    "    except Exception as e:\n",
    "        print(f\"Migration note: {e}\")\n",
    "    \n",
    " \n",
    "    print(\"\\n[4/5] Loading and Cleaning CSV data...\")\n",
    "\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(DATA_DIR / \"cyber_incidents.csv\")\n",
    "        \n",
    "       \n",
    "        df = df.rename(columns={\n",
    "            \"Date\": \"date\", \n",
    "            \"Type\": \"incident_type\", \n",
    "            \"Description\": \"description\"\n",
    "        })\n",
    "        \n",
    "      \n",
    "        df[\"severity\"] = \"Medium\"\n",
    "        df[\"status\"] = \"Open\"\n",
    "        df[\"reported_by\"] = \"alice\"\n",
    "     \n",
    "        valid_columns = [\"date\", \"incident_type\", \"severity\", \"status\", \"description\", \"reported_by\"]\n",
    "        df_clean = df[valid_columns]\n",
    "        \n",
    "        df_clean.to_sql(\"cyber_incidents\", conn, if_exists=\"append\", index=False)\n",
    "        print(f\"‚úÖ Loaded {len(df_clean)} cleaned rows into 'cyber_incidents'\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing cyber_incidents: {e}\")\n",
    "\n",
    "   \n",
    "    load_csv_to_table(conn, DATA_DIR / \"datasets_metadata.csv\", \"datasets_metadata\")\n",
    "    load_csv_to_table(conn, DATA_DIR / \"it_tickets.csv\", \"it_tickets\")\n",
    "    \n",
    "    \n",
    "    print(\"\\n[5/5] Verifying...\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM it_tickets\")\n",
    "    print(f\"‚úÖ IT Tickets Row Count: {cursor.fetchone()[0]}\")\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"\\nDATABASE SETUP COMPLETE!\")\n",
    "\n",
    "\n",
    "setup_database_complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 10: Testing & Verification\n",
    "\n",
    "### Step 10.1: Comprehensive Database Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive_test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üß™ RUNNING COMPREHENSIVE TESTS\n",
      "============================================================\n",
      "\n",
      "[TEST 1] Authentication\n",
      "  Register: ‚úÖ User 'test_user' registered successfully!\n",
      "  Login:    ‚úÖ Welcome, test_user!\n",
      "\n",
      "[TEST 2] CRUD Operations\n",
      "  Create: ‚úÖ Incident #963 created\n",
      "  Read:    Found incident #963\n",
      "  Update:  Status updated\n",
      "  Delete:  Incident deleted\n",
      "\n",
      "[TEST 3] Analytical Queries\n",
      "  By Type:     Found 8 incident types\n",
      "  High Severity: Found 0 status categories\n",
      "\n",
      "============================================================\n",
      "‚úÖ ALL TESTS PASSED!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def run_comprehensive_tests():\n",
    "    \"\"\"\n",
    "    Run comprehensive tests on your database.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üß™ RUNNING COMPREHENSIVE TESTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    conn = connect_database()\n",
    "    \n",
    "    # Test 1: Authentication\n",
    "    print(\"\\n[TEST 1] Authentication\")\n",
    "    success, msg = register_user(\"test_user\", \"TestPass123!\", \"user\")\n",
    "    print(f\"  Register: {'‚úÖ' if success else '‚ùå'} {msg}\")\n",
    "    \n",
    "    success, msg = login_user(\"test_user\", \"TestPass123!\")\n",
    "    print(f\"  Login:    {'‚úÖ' if success else '‚ùå'} {msg}\")\n",
    "    \n",
    "    # Test 2: CRUD Operations\n",
    "    print(\"\\n[TEST 2] CRUD Operations\")\n",
    "    \n",
    "    # Create\n",
    "    test_id = insert_incident(\n",
    "        conn,\n",
    "        \"2024-11-05\",\n",
    "        \"Test Incident\",\n",
    "        \"Low\",\n",
    "        \"Open\",\n",
    "        \"This is a test incident\",\n",
    "        \"test_user\"\n",
    "    )\n",
    "    print(f\"  Create: ‚úÖ Incident #{test_id} created\")\n",
    "    \n",
    "    # Read\n",
    "    df = pd.read_sql_query(\n",
    "        \"SELECT * FROM cyber_incidents WHERE id = ?\",\n",
    "        conn,\n",
    "        params=(test_id,)\n",
    "    )\n",
    "    print(f\"  Read:    Found incident #{test_id}\")\n",
    "    \n",
    "    # Update\n",
    "    update_incident_status(conn, test_id, \"Resolved\")\n",
    "    print(f\"  Update:  Status updated\")\n",
    "    \n",
    "    # Delete\n",
    "    delete_incident(conn, test_id)\n",
    "    print(f\"  Delete:  Incident deleted\")\n",
    "    \n",
    "    # Test 3: Analytical Queries\n",
    "    print(\"\\n[TEST 3] Analytical Queries\")\n",
    "    \n",
    "    df_by_type = get_incidents_by_type_count(conn)\n",
    "    print(f\"  By Type:     Found {len(df_by_type)} incident types\")\n",
    "    \n",
    "    df_high = get_high_severity_by_status(conn)\n",
    "    print(f\"  High Severity: Found {len(df_high)} status categories\")\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ ALL TESTS PASSED!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Run tests\n",
    "run_comprehensive_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Congratulations!\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "You've successfully:\n",
    "\n",
    " **Migrated** from file-based storage to a professional SQLite database  \n",
    " **Created** a complete database schema with 4 tables  \n",
    " **Implemented** secure authentication with bcrypt  \n",
    " **Loaded** CSV data efficiently using pandas  \n",
    " **Built** CRUD functions for all database operations  \n",
    " **Secured** your queries against SQL injection  \n",
    " **Extracted** insights using analytical SQL queries  \n",
    "\n",
    "### Your Database Structure\n",
    "\n",
    "```\n",
    "intelligence_platform.db\n",
    "‚îú‚îÄ users                 (authentication)\n",
    "‚îú‚îÄ cyber_incidents       (security domain)\n",
    "‚îú‚îÄ datasets_metadata     (data domain)\n",
    "‚îî‚îÄ it_tickets            (IT domain)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  Next Steps: Week 9 Preview\n",
    "\n",
    "### What's Coming in Week 9\n",
    "\n",
    "Next week, you'll build a **Streamlit web interface** that uses your database:\n",
    "\n",
    "1. **Login Page** ‚Äî Use your `login_user()` function\n",
    "2. **Dashboard** ‚Äî Display incident statistics with charts\n",
    "3. **CRUD Forms** ‚Äî Interactive forms for creating/updating incidents\n",
    "4. **Visualizations** ‚Äî Use Plotly to create interactive charts\n",
    "5. **Session Management** ‚Äî Keep users logged in across pages\n",
    "\n",
    "### Preparing for Week 9\n",
    "\n",
    "Make sure your database is working correctly:\n",
    "-  All tables created\n",
    "-  Data loaded from CSVs\n",
    "-  CRUD operations tested\n",
    "-  Queries returning correct results\n",
    "\n",
    "---\n",
    "\n",
    "##  Submission Checklist\n",
    "\n",
    "Before submitting your Week 8 work, ensure you have:\n",
    "\n",
    "### Files to Submit\n",
    "\n",
    "- [ ] `app/data/db.py` ‚Äî Database connection functions\n",
    "- [ ] `app/data/schema.py` ‚Äî CREATE TABLE statements\n",
    "- [ ] `app/data/users.py` ‚Äî User CRUD functions\n",
    "- [ ] `app/data/incidents.py` ‚Äî Incident CRUD functions\n",
    "- [ ] `app/data/datasets.py` ‚Äî Dataset CRUD functions\n",
    "- [ ] `app/data/tickets.py` ‚Äî Ticket CRUD functions\n",
    "- [ ] `app/services/user_service.py` ‚Äî User migration function\n",
    "- [ ] `main.py` ‚Äî Demo script showing all CRUD operations\n",
    "- [ ] `DATA/intelligence_platform.db` ‚Äî Your populated database\n",
    "- [ ] `requirements.txt` ‚Äî Updated with pandas, bcrypt\n",
    "- [ ] `docs/README.md` ‚Äî Documentation with screenshots\n",
    "\n",
    "### Testing Checklist\n",
    "\n",
    "- [ ] Database connects successfully\n",
    "- [ ] All 4 tables created\n",
    "- [ ] Users migrated from users.txt\n",
    "- [ ] CSV data loaded\n",
    "- [ ] Registration works\n",
    "- [ ] Login works\n",
    "- [ ] Can create new incidents\n",
    "- [ ] Can read/query incidents\n",
    "- [ ] Can update incident status\n",
    "- [ ] Can delete incidents\n",
    "- [ ] Analytical queries return results\n",
    "- [ ] No SQL injection vulnerabilities (all queries use `?` placeholders)\n",
    "\n",
    "---\n",
    "\n",
    "##  Tips & Best Practices\n",
    "\n",
    "### Database Best Practices\n",
    "\n",
    "1. **Always close connections** when done\n",
    "2. **Use parameterized queries** (never string formatting)\n",
    "3. **Commit after writes** (INSERT, UPDATE, DELETE)\n",
    "4. **Use transactions** for multiple related operations\n",
    "5. **Index frequently queried columns** (for performance)\n",
    "\n",
    "### Debugging Tips\n",
    "\n",
    "If something doesn't work:\n",
    "\n",
    "1. **Check the error message** ‚Äî SQL errors are usually descriptive\n",
    "2. **Print your SQL** ‚Äî Use `print(query)` to see what's being executed\n",
    "3. **Test queries in DB Browser** ‚Äî Use a GUI tool to test SQL\n",
    "4. **Check data types** ‚Äî Make sure your Python types match SQL types\n",
    "5. **Verify file paths** ‚Äî Use absolute paths or check current directory\n",
    "\n",
    "### Common Errors\n",
    "\n",
    "| Error | Cause | Solution |\n",
    "|-------|-------|----------|\n",
    "| `table already exists` | Running CREATE TABLE twice | Use `IF NOT EXISTS` |\n",
    "| `UNIQUE constraint failed` | Duplicate username/ID | Check before INSERT |\n",
    "| `no such table` | Table not created | Run CREATE TABLE first |\n",
    "| `no such column` | Typo in column name | Check table schema |\n",
    "| `database is locked` | Connection not closed | Always close connections |\n",
    "\n",
    "---\n",
    "\n",
    "##  Additional Resources\n",
    "\n",
    "### SQLite Documentation\n",
    "- [SQLite Official Docs](https://www.sqlite.org/docs.html)\n",
    "- [Python sqlite3 Module](https://docs.python.org/3/library/sqlite3.html)\n",
    "\n",
    "### SQL Learning Resources\n",
    "- [W3Schools SQL Tutorial](https://www.w3schools.com/sql/)\n",
    "- [SQLite Tutorial](https://www.sqlitetutorial.net/)\n",
    "\n",
    "### Tools\n",
    "- [DB Browser for SQLite](https://sqlitebrowser.org/) ‚Äî GUI for viewing/editing databases\n",
    "- [SQLite Viewer (VS Code Extension)](https://marketplace.visualstudio.com/items?itemName=alexcvzz.vscode-sqlite)\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
